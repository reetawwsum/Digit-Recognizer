Observations & Experimentations
===============================

1. Reading the train file, and converting the data into int before pickle to disk, results in formation of 1.05 GB file, in contrast to 51 MB file size of train file.
2. Using string type before pickle to disk, results in formation of 264 MB file.
3. Reading all of train and test data while coding is not optimal.
4. train dataset (42000, 784)
test dataset (28000, 784)
5. Adding functionality to get subset of dataset.
6. Splitting train dataset into train-validation dataset for cross validation.
7. Experimenting with various ANN architecture:
	a. Linear Model
	Input Layer -- Output Layer
	   (784)		  (10)
	   
	Output with various learning rate:
		i. 0.5
		Minibatch loss at step 0: 290.819824
		  Training Accuracy: 16.4%
		  Validation Accuracy: 34.2%
		Minibatch loss at step 500: 7488.650879
		  Training Accuracy: 84.4%
		  Validation Accuracy: 81.4%
		Minibatch loss at step 1000: 4111.408203
		  Training Accuracy: 92.2%
		  Validation Accuracy: 89.9%
		Minibatch loss at step 1500: 1973.520874
		  Training Accuracy: 93.8%
		  Validation Accuracy: 88.7%
		Minibatch loss at step 2000: 4977.421875
		  Training Accuracy: 87.5%
		  Validation Accuracy: 88.7%
		Minibatch loss at step 2500: 3449.632812
		  Training Accuracy: 93.0%
		  Validation Accuracy: 88.5%
		Minibatch loss at step 3000: 4594.892578
		  Training Accuracy: 90.6%
		  Validation Accuracy: 87.5%

		ii. 0.1
		Minibatch loss at step 0: 396.500275
		  Training Accuracy: 6.2%
		  Validation Accuracy: 20.1%
		Minibatch loss at step 500: 2282.356689
		  Training Accuracy: 82.0%
		  Validation Accuracy: 83.4%
		Minibatch loss at step 1000: 860.771606
		  Training Accuracy: 90.6%
		  Validation Accuracy: 87.7%
		Minibatch loss at step 1500: 657.445190
		  Training Accuracy: 89.8%
		  Validation Accuracy: 86.8%
		Minibatch loss at step 2000: 2017.726562
		  Training Accuracy: 85.9%
		  Validation Accuracy: 89.3%
		Minibatch loss at step 2500: 867.989563
		  Training Accuracy: 89.8%
		  Validation Accuracy: 90.1%
		Minibatch loss at step 3000: 580.059814
		  Training Accuracy: 93.0%
		  Validation Accuracy: 87.9%

		iii. 0.05
		Minibatch loss at step 0: 312.387268
		  Training Accuracy: 12.5%
		  Validation Accuracy: 26.9%
		Minibatch loss at step 500: 452.893188
		  Training Accuracy: 89.1%
		  Validation Accuracy: 90.4%
		Minibatch loss at step 1000: 445.309418
		  Training Accuracy: 89.8%
		  Validation Accuracy: 88.1%
		Minibatch loss at step 1500: 296.761963
		  Training Accuracy: 91.4%
		  Validation Accuracy: 87.5%
		Minibatch loss at step 2000: 1134.573364
		  Training Accuracy: 84.4%
		  Validation Accuracy: 89.2%
		Minibatch loss at step 2500: 480.196198
		  Training Accuracy: 92.2%
		  Validation Accuracy: 87.6%
		Minibatch loss at step 3000: 268.621826
		  Training Accuracy: 93.0%
		  Validation Accuracy: 88.0%

		iv. 0.01
		Minibatch loss at step 0: 336.872162
		  Training Accuracy: 7.8%
		  Validation Accuracy: 25.2%
		Minibatch loss at step 500: 77.321243
		  Training Accuracy: 87.5%
		  Validation Accuracy: 87.7%
		Minibatch loss at step 1000: 92.064682
		  Training Accuracy: 86.7%
		  Validation Accuracy: 88.8%
		Minibatch loss at step 1500: 69.735123
		  Training Accuracy: 89.8%
		  Validation Accuracy: 88.2%
		Minibatch loss at step 2000: 225.731873
		  Training Accuracy: 85.2%
		  Validation Accuracy: 89.0%
		Minibatch loss at step 2500: 87.068810
		  Training Accuracy: 89.8%
		  Validation Accuracy: 87.7%
		Minibatch loss at step 3000: 96.718430
		  Training Accuracy: 89.8%
		  Validation Accuracy: 89.2%